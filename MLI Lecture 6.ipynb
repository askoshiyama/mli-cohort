{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirements !pip freeze > requirements.txt.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Organise data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/askoshiyama/mli-cohort/master/german_credit.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variables\n",
    "cat_variables = ['account_check_status', 'credit_history', 'purpose', 'savings', 'present_emp_since', 'personal_status_sex',\n",
    "                'property', 'other_installment_plans', 'housing', 'job', 'telephone', \"other_debtors\", 'foreign_worker']\n",
    "\n",
    "# target variable\n",
    "output_variable = [\"default\"]\n",
    "\n",
    "# other integer variables\n",
    "int_variables = ['credits_this_bank', 'present_res_since', 'duration_in_month', 'people_under_maintenance', \n",
    "                 'installment_as_income_perc', 'age', 'credit_amount']\n",
    "# list(set(df.columns) - set(output_variable) - set(cat_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding fitting\n",
    "one_hot_func = OneHotEncoder().fit(df[cat_variables])\n",
    "\n",
    "# mapping\n",
    "cat_mapped = one_hot_func.transform(df[cat_variables]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-allocation\n",
    "df_cat = pd.DataFrame(index=df.index)\n",
    "\n",
    "# one-hot encoding of categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# I will do a loop for pedagogical reasons, but it is not entirely necessary\n",
    "for cat in cat_variables:\n",
    "    # one-hot encoding fitting\n",
    "    one_hot_func = OneHotEncoder().fit(df[[cat]])\n",
    "    \n",
    "    # mapping\n",
    "    cat_mapped = one_hot_func.transform(df[[cat]]).toarray()\n",
    "    \n",
    "    # storing\n",
    "    for (k, cat_label) in enumerate(one_hot_func.categories_[0]):\n",
    "        df_cat[cat + \"_\" + cat_label] = cat_mapped[:, k]\n",
    "\n",
    "# quick check\n",
    "df_cat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bracketing integer variable - age\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbin_func = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='quantile').fit(df[[\"age\"]])\n",
    "df_age = pd.DataFrame(kbin_func.transform(df[[\"age\"]]).toarray(), columns=[\"young\", \"adult\", \"senior\"])\n",
    "\n",
    "# checking\n",
    "pd.concat([df_age, df[[\"age\"]]], axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other types of transformations possible - log transformation \n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "log_mapping = FunctionTransformer(func=np.log, inverse_func=np.exp)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.hist(df[\"credit_amount\"])\n",
    "ax1.set_title(\"Pre-transformation\")\n",
    "\n",
    "ax2.hist(log_mapping.transform(df[\"credit_amount\"]))\n",
    "ax2.set_title(\"After log-transformation\")\n",
    "df_log = pd.DataFrame(log_mapping.transform(df[\"credit_amount\"]).values, columns=[\"log(credit)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidating a final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.concat([df[int_variables[:-2]], df_cat, df_age, df_log, df[output_variable]], axis=1)\n",
    "df.shape, df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: PCA, t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X, y = df_model.drop(labels=output_variable, axis=1).values, df_model[output_variable].values\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "print('explained variance ratio (first two components): %s'\n",
    "      % str(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.figure()\n",
    "colors = ['navy', 'turquoise']\n",
    "target_names = [\"No Default\", \"Default\"]\n",
    "lw = 2\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1], target_names):\n",
    "    plt.scatter(X_r[(y == i).ravel(), 0], X_r[(y == i).ravel(), 1], color=color, alpha=.8, lw=lw, label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of German Credit dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X, y = df_model.drop(labels=output_variable, axis=1).values, df_model[output_variable].values\n",
    "tsne = TSNE(n_components=2, init='random', random_state=0, perplexity=5)\n",
    "X_r = tsne.fit_transform(X)\n",
    "\n",
    "plt.figure()\n",
    "colors = ['navy', 'turquoise']\n",
    "target_names = [\"No Default\", \"Default\"]\n",
    "lw = 2\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1], target_names):\n",
    "    plt.scatter(X_r[(y == i).ravel(), 0], X_r[(y == i).ravel(), 1], color=color, alpha=.8, lw=lw, label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('t-SNE of German Credit dataset')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SVM: Grid-search + Stratified K-fold-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# params\n",
    "k_folds = StratifiedKFold(n_splits=3, random_state=10) # 3-fold -\n",
    "\n",
    "hyper_params = {\"kernel_svc__C\": [10.00 ** 2, 10.00 ** 3, 10.00 ** 4], # 5\n",
    "                \"kernel_svc__gamma\": (np.array([10.0 ** -2, 10.0 ** -1, 10.0 ** 0, 10.0 ** 1, 10.0 ** 2]) * 1.0/df_model.shape[1]).tolist(),\n",
    "                # [10.0 ** -3, 10.0 ** -2, 10.0 ** -1, 10.0 ** 0, 10.0 ** 1] * 1.0/df_model.shape[1],\n",
    "                \"kernel_svc__kernel\": [\"rbf\"], # rbf (radial basis function) a.k.a. gaussian kernel\n",
    "                \"kernel_svc__probability\": [True]\n",
    "                }\n",
    "\n",
    "# = 75 models in total\n",
    "\n",
    "# performance metrics\n",
    "perf_metrics = {\"Accuracy\": metrics.accuracy_score, \n",
    "                \"Precision\": metrics.precision_score, \n",
    "                \"Recall\": metrics.recall_score,\n",
    "                \"AUC\": metrics.roc_auc_score, \n",
    "                \"F1-Score\": metrics.f1_score, \n",
    "                \"Brier\": metrics.brier_score_loss\n",
    "               }\n",
    "for pf in perf_metrics:\n",
    "    perf_metrics[pf] = metrics.make_scorer(perf_metrics[pf])\n",
    "\n",
    "# main method\n",
    "# split the data into inputs and output\n",
    "X, y = df_model.drop(labels=output_variable, axis=1).values, df_model[output_variable].values\n",
    "\n",
    "# instantiate the model - Pipeline where we scale the variables using StandardScaler = (x - mu)/sigma; kernel SVM\n",
    "model_pipeline = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                           (\"kernel_svc\", SVC())]\n",
    "                         )\n",
    "\n",
    "# run the grid-search CV procedure\n",
    "model = GridSearchCV(estimator=model_pipeline, \n",
    "                     param_grid=hyper_params, \n",
    "                     scoring=perf_metrics, \n",
    "                     cv=k_folds, \n",
    "                     refit=\"F1-Score\"\n",
    "                    )\n",
    "model.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - done by GridSearchCV\n",
    "# for every hyperparameter\n",
    "## for every (train, test) fold\n",
    "### model_pipeline.fit(X[train], y[train])\n",
    "### model_pipelin.predict(X[test], y[test])\n",
    "### compute performance metrics\n",
    "### store results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best model\n",
    "best_model = model.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all results and avg results in a df\n",
    "df_cv = pd.DataFrame(model.cv_results_)\n",
    "\n",
    "# add a hyperparameter column in avg df\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "df_hyperparams = pd.DataFrame(list(ParameterGrid(model.param_grid)))\n",
    "df_avgcv = pd.DataFrame(columns=perf_metrics.keys())\n",
    "for pf in perf_metrics.keys():\n",
    "    df_avgcv[pf] = df_cv[\"mean_test_\" + pf]\n",
    "df_avgcv = pd.concat([df_hyperparams, df_avgcv], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=\"kernel_svc__C\", y=\"F1-Score\", data=df_avgcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=\"kernel_svc__gamma\", y=\"F1-Score\", data=df_avgcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avgcv.loc[df_avgcv[\"F1-Score\"].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "feat_imp = permutation_importance(best_model, X, y, n_repeats=5, random_state=10)\n",
    "\n",
    "df_featimp = pd.DataFrame({\"Variable\": df_model.drop(output_variable, axis=1).columns,\n",
    "                           \"Importance\": feat_imp['importances_mean']/feat_imp[\"importances_mean\"].max()})\n",
    "\n",
    "df_featimp = df_featimp.sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "# chart\n",
    "df_featimp.iloc[:5].plot(x=\"Variable\", y=\"Importance\", kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial dependence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "z = pd.DataFrame(X, columns=df_model.drop(output_variable, axis=1).columns)\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "plot_partial_dependence(best_model, z, df_featimp[\"Variable\"].iloc[:5], \n",
    "                        ax=ax, response_method=\"predict_proba\", \n",
    "                        method=\"brute\", grid_resolution=200\n",
    "                       ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "plot_partial_dependence(best_model, z, [(df_featimp[\"Variable\"].iloc[0], df_featimp[\"Variable\"].iloc[2])], \n",
    "                        fig=fig, response_method=\"predict_proba\", method=\"brute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X, y = df_model.drop(labels=output_variable, axis=1).values, best_model.predict(X)\n",
    "tsne = TSNE(n_components=2, init='random', random_state=0, perplexity=10)\n",
    "X_r = tsne.fit_transform(X)\n",
    "\n",
    "plt.figure()\n",
    "colors = ['navy', 'turquoise']\n",
    "target_names = [\"No Default\", \"Default\"]\n",
    "lw = 2\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1], target_names):\n",
    "    plt.scatter(X_r[(y == i).ravel(), 0], X_r[(y == i).ravel(), 1], color=color, alpha=.8, lw=lw, label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('t-SNE of German Credit dataset - Predicted')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X, y = df_model.drop(labels=output_variable, axis=1).values, df_model[output_variable].values\n",
    "tsne = TSNE(n_components=2, init='random', random_state=0, perplexity=10)\n",
    "X_r = tsne.fit_transform(X)\n",
    "\n",
    "plt.figure()\n",
    "colors = ['navy', 'turquoise']\n",
    "target_names = [\"No Default\", \"Default\"]\n",
    "lw = 2\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1], target_names):\n",
    "    plt.scatter(X_r[(y == i).ravel(), 0], X_r[(y == i).ravel(), 1], color=color, alpha=.8, lw=lw, label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('t-SNE of German Credit dataset - Observed')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing optimism bias in hyper-parameter optimization, and comparing strategies: Nested Cross-Validation/Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCC(y_true, y_pred):\n",
    "\n",
    "    # confusion matrix components\n",
    "    TP = sum((y_true.ravel()==1) * (y_pred.ravel()==1)) # catch the criminal\n",
    "    TN = sum((y_true.ravel()==0) * (y_pred.ravel()==0)) # there was no criminal\n",
    "    FP = sum((y_true.ravel()==0) * (y_pred.ravel()==1)) # false alarm\n",
    "    FN = sum((y_true.ravel()==1) * (y_pred.ravel()==0)) # broken alarm\n",
    "    \n",
    "    # numerator\n",
    "    Num = (TP * TN - FP * FN)\n",
    "    \n",
    "    # denominator\n",
    "    Den = np.sqrt(TP + FP)*np.sqrt(TP + FN)*np.sqrt(TN + FP)*np.sqrt(TN + FN)\n",
    "    \n",
    "    return Num/Den # Num/Den\n",
    "\n",
    "class KPI:\n",
    "    def __init__(self, loan):\n",
    "        self.loan = loan\n",
    "    \n",
    "    def KPI(self, y_true, y_pred):\n",
    "        amount_repaid = (y_true.ravel()==1) * (y_pred.ravel()==1) * self.loan\n",
    "        amount_loss = (y_true.ravel()==0) * (y_pred.ravel()==1) * self.loan\n",
    "        return np.sum(amount_repaid - amount_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi = KPI(np.exp(df_model[\"log(credit)\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi.KPI((np.random.rand(1000) > 0.5) * 1, (np.random.rand(1000) > 0.5) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# k-fold params\n",
    "inner_folds = StratifiedKFold(n_splits=3, random_state=10) # inner k-fold\n",
    "outer_folds = StratifiedKFold(n_splits=2, random_state=10) # outer k-fold\n",
    "\n",
    "# models\n",
    "model_dict = {\"GBT\": GradientBoostingClassifier(random_state=10),\n",
    "              \"Tree\": DecisionTreeClassifier(random_state=10),\n",
    "              \n",
    "              \"MLP\": Pipeline([(\"std\", StandardScaler()), \n",
    "                               (\"mlp\", MLPClassifier(random_state=10))]),\n",
    "              \n",
    "              \"KNN\": Pipeline([(\"std\", StandardScaler()),\n",
    "                               (\"knn\", KNeighborsClassifier())]),\n",
    "              \n",
    "              \"Logistic\": LogisticRegression(penalty=\"none\", solver=\"lbfgs\"),\n",
    "              \"LassoLogistic\": Pipeline([(\"std\", StandardScaler()), \n",
    "                                         (\"lasso\", LogisticRegression(penalty=\"l1\", solver='liblinear'))]),\n",
    "              \"ElasticNet\": Pipeline([(\"std\", StandardScaler()), \n",
    "                                      (\"en\", LogisticRegression(penalty=\"elasticnet\", solver=\"saga\"))]),\n",
    "              \"UnifRandom\": DummyClassifier(strategy=\"uniform\"), \n",
    "              \"StratRandom\": DummyClassifier(strategy=\"stratified\"),\n",
    "              \"SVM\": Pipeline([(\"std\", StandardScaler()), \n",
    "                               (\"svc\", SVC(kernel=\"rbf\", probability=True))]),\n",
    "              #\"Naive Bayes\": GaussianNB()\n",
    "             }\n",
    "\n",
    "# models hyperparams\n",
    "hyper_params = {\"GBT\": {\"learning_rate\": [10.0 ** -1, 10.0 ** 0, 2.0],\n",
    "                        \"max_depth\": [1, 2, 3],\n",
    "                        \"max_features\": [0.1, 0.25, 0.5],\n",
    "                        \"n_estimators\": [200]},\n",
    "                \n",
    "                \"Tree\": {\"max_depth\": [1, 3, 5, 7, 9],\n",
    "                         \"class_weight\": [None, \"balanced\"]},\n",
    "                \n",
    "                \"MLP\": {\"mlp__hidden_layer_sizes\": [(5,), (10,), (50,)], \n",
    "                        \"mlp__activation\": ['relu', 'tanh']\n",
    "                       },\n",
    "                \"KNN\": {\"knn__n_neighbors\": [1, 3, 5, 7]\n",
    "                       },\n",
    "                \"Logistic\": {\"class_weight\": [None, \"balanced\"]},\n",
    "                \n",
    "                \"LassoLogistic\": {\"lasso__C\": [10.0 ** -4, 10.0 ** -3, 10.0 ** -2, 10.0 ** -1, 10.0 ** 0],\n",
    "                                  \"lasso__class_weight\": [None, \"balanced\"]},\n",
    "                \n",
    "                \"ElasticNet\": {\"en__C\": [10.0 ** -4, 10.0 ** -3, 10.0 ** -2, 10.0 ** -1, 10.0 ** -0],\n",
    "                               \"en__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "                               \"en__class_weight\": [None, \"balanced\"]},\n",
    "                \n",
    "                \"UnifRandom\": {},\n",
    "                \"StratRandom\": {},\n",
    "                \n",
    "                \"SVM\": {\"svc__C\": [10.0 ** -2, 10.0 ** -1, 10.0 ** 0, 10.0 ** 1, 10.00 ** 2], \n",
    "                        \"svc__gamma\": (np.array([10.0 ** -2, 10.0 ** -1, 10.0 ** 0, 10.0 ** 1, 10.0 ** 2]) * 1.0/df_model.shape[1]).tolist(),\n",
    "                        \"svc__class_weight\": [None, \"balanced\"]}\n",
    "                #\"Naive Bayes\": {}\n",
    "                }\n",
    "\n",
    "# performance metrics\n",
    "perf_metrics = {\"Accuracy\": metrics.accuracy_score, \n",
    "                \"Precision\": metrics.precision_score, \n",
    "                \"Recall\": metrics.recall_score,\n",
    "                \"AUC\": metrics.roc_auc_score, \n",
    "                \"F1-Score\": metrics.f1_score, \n",
    "                \"Brier\": metrics.brier_score_loss,\n",
    "                \"MCC\": MCC,\n",
    "                \"KPI\": KPI(np.exp(df_model[\"log(credit)\"].values)).KPI\n",
    "               }\n",
    "scorer_metrics = {}\n",
    "for pf in perf_metrics:\n",
    "    scorer_metrics[pf] = metrics.make_scorer(perf_metrics[pf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-allocation\n",
    "X, y = df_model.drop(labels=output_variable, axis=1).values, df_model[output_variable].values\n",
    "k, z, innercv_results, inner_best_model = 0, 0, {}, {}\n",
    "df_outer_results = pd.DataFrame(index=[0], columns=[\"Model\"] + list(perf_metrics.keys()))\n",
    "\n",
    "# outer loop\n",
    "for (out_train, out_test) in outer_folds.split(X, y):\n",
    "    # separation: train, test\n",
    "    Xtrain, Xtest = X[out_train], X[out_test]\n",
    "    ytrain, ytest = y[out_train], y[out_test]\n",
    "        \n",
    "    # inner loop -- all models -- hyperparameter fine-tuning\n",
    "    innercv_results[\"fold_\" + str(k)] = {}\n",
    "    inner_best_model[\"fold_\" + str(k)] = {}\n",
    "    \n",
    "    for class_model in model_dict.keys():\n",
    "        print((k, class_model))\n",
    "        innercv_results[\"fold_\" + str(k)][class_model] = GridSearchCV(estimator=model_dict[class_model], \n",
    "                                                                       param_grid=hyper_params[class_model], \n",
    "                                                                       scoring=scorer_metrics, \n",
    "                                                                       cv=inner_folds, \n",
    "                                                                       refit=\"MCC\")\n",
    "        innercv_results[\"fold_\" + str(k)][class_model].fit(Xtrain, ytrain.ravel())\n",
    "        inner_best_model[\"fold_\" + str(k)][class_model] = innercv_results[\"fold_\" + str(k)][class_model].best_estimator_\n",
    "    \n",
    "    # prediction -- all models -- compute performance metrics at the same level playing field\n",
    "    for class_model in model_dict.keys():\n",
    "        # prediction\n",
    "        ypred_class = inner_best_model[\"fold_\" + str(k)][class_model].predict(Xtest)\n",
    "        ypred_prob = inner_best_model[\"fold_\" + str(k)][class_model].predict_proba(Xtest)[:, 1]\n",
    "        df_outer_results.loc[z, \"Model\"] = class_model\n",
    "    \n",
    "        # compute performance metrics\n",
    "        for pf in perf_metrics.keys():\n",
    "            if pf in [\"AUC\", \"Brier\"]:\n",
    "                df_outer_results.loc[z, pf] = perf_metrics[pf](ytest, ypred_prob)\n",
    "            else:\n",
    "                df_outer_results.loc[z, pf] = perf_metrics[pf](ytest, ypred_class)\n",
    "        z += 1\n",
    "    \n",
    "    # iteration\n",
    "    k += 1\n",
    "\n",
    "# final organisation\n",
    "df_outer_results[list(perf_metrics.keys())] = df_outer_results[list(perf_metrics.keys())].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer_results[list(perf_metrics.keys())] = df_outer_results[list(perf_metrics.keys())].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer_results.pivot_table(index=[\"Model\"], aggfunc=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer_results.pivot_table(index=[\"Model\"], aggfunc=\"mean\").rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(13,5))\n",
    "sns.pointplot(x=\"Model\", y=\"MCC\", data=df_outer_results, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt = df_outer_results.melt(id_vars=[\"Model\"], value_vars=list(perf_metrics.keys()))\n",
    "fig, ax = plt.subplots(1,1,figsize=(13,5))\n",
    "sns.pointplot(x=\"Model\", y=\"value\", hue=\"variable\", data=df_melt, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer_results.pivot_table(index=[\"Model\"], aggfunc=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_outer_results.pivot_table(index=[\"Model\"], aggfunc=\"mean\")\n",
    "a[[\"Brier\"]] = 1 - a[[\"Brier\"]]\n",
    "a.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.rank().mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalable models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset with different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small\n",
    "df_model_small = df_model.copy()\n",
    "\n",
    "# medium\n",
    "for k in range(10):\n",
    "    if k==0:\n",
    "        df_model_medium = df_model.copy()\n",
    "    else:\n",
    "        df_model_medium = pd.concat([df_model_medium, df_model.copy()], axis=0, ignore_index=True)\n",
    "        \n",
    "# large\n",
    "for k in range(100):\n",
    "    if k==0:\n",
    "        df_model_large = df_model.copy()\n",
    "    else:\n",
    "        df_model_large = pd.concat([df_model_large, df_model.copy()], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# small\n",
    "start = time()\n",
    "GradientBoostingClassifier(n_estimators=100).fit(df_model_small.drop(output_variable, axis=1), \n",
    "                                                 df_model_small[output_variable])\n",
    "print(time() - start)\n",
    "\n",
    "# medium\n",
    "start = time()\n",
    "GradientBoostingClassifier(n_estimators=100).fit(df_model_medium.drop(output_variable, axis=1), \n",
    "                                                 df_model_medium[output_variable])\n",
    "print(time() - start)\n",
    "\n",
    "# large\n",
    "start = time()\n",
    "GradientBoostingClassifier(n_estimators=100).fit(df_model_large.drop(output_variable, axis=1), \n",
    "                                                 df_model_large[output_variable])\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM - https://lightgbm.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from time import time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# small\n",
    "start = time()\n",
    "LGBMClassifier(n_estimators=100).fit(df_model_small.drop(output_variable, axis=1).values, \n",
    "                                                 df_model_small[output_variable].values)\n",
    "print(time() - start)\n",
    "\n",
    "# medium\n",
    "start = time()\n",
    "LGBMClassifier(n_estimators=100).fit(df_model_medium.drop(output_variable, axis=1).values, \n",
    "                                                 df_model_medium[output_variable].values)\n",
    "print(time() - start)\n",
    "\n",
    "# large\n",
    "start = time()\n",
    "LGBMClassifier(n_estimators=100).fit(df_model_large.drop(output_variable, axis=1).values, \n",
    "                                                 df_model_large[output_variable].values)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (SGDClassifier, Linear SVM) + Feature Mapping - almost a kernel approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nystroem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import Nystroem\n",
    "nyst = Nystroem(gamma=0.001, n_components=2)\n",
    "nyst.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_model.drop(labels=output_variable, axis=1).values, df_model[output_variable].values\n",
    "nyst = Nystroem(gamma=.01, n_components=2)\n",
    "X_r = nyst.fit_transform(X)\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "print('explained variance ratio (first two components): %s'\n",
    "      % str(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.figure()\n",
    "colors = ['navy', 'turquoise']\n",
    "target_names = [\"No Default\", \"Default\"]\n",
    "lw = 2\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1], target_names):\n",
    "    plt.scatter(X_r[(y == i).ravel(), 0], X_r[(y == i).ravel(), 1], color=color, alpha=.8, lw=lw, label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of German Credit dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# k-fold params\n",
    "inner_folds = StratifiedKFold(n_splits=3, random_state=10) # inner k-fold\n",
    "outer_folds = StratifiedKFold(n_splits=5, random_state=10) # outer k-fold\n",
    "\n",
    "# models\n",
    "model_dict = {\"LightGBM\": LGBMClassifier(random_state=10),\n",
    "              \"SGD\": Pipeline([(\"std\", StandardScaler()),\n",
    "                               (\"map\", Nystroem(random_state=10)),\n",
    "                               (\"sgd\", SGDClassifier(random_state=10))]),\n",
    "              \"LinearSVM\": Pipeline([(\"std\", StandardScaler()),\n",
    "                                     (\"map\", Nystroem(random_state=10)),\n",
    "                                     (\"sgd\", LinearSVC(dual=False, random_state=10))])\n",
    "             }\n",
    "\n",
    "# models hyperparams\n",
    "hyper_params = {\"LightGBM\": {\"learning_rate\": [10.0 ** -1, 10.0 ** 0, 2.0],\n",
    "                             \"max_depth\": [1, 2, 3],\n",
    "                             #\"max_features\": [0.1, 0.25, 0.5],\n",
    "                             \"n_estimators\": [200]},\n",
    "                \"SGD\": {\"sgd__loss\": [\"hinge\", \"log\"],\n",
    "                        \"sgd__alpha\": [0.01, 0.1, 1.0, 10.0],\n",
    "                        \"sgd__class_weight\": [None, \"balanced\"],\n",
    "                        \"sgd__eta0\": [0.001, 0.01, 0.1],\n",
    "                        \"sgd__max_iter\": [100],\n",
    "                        \"map__gamma\": [0.0001, 0.001, 0.01, 0.1]},\n",
    "                \"LinearSVM\": {\"sgd__C\": [0.01, 0.1, 1.0, 10.0],\n",
    "                              \"sgd__class_weight\": [None, \"balanced\"],\n",
    "                              \"map__gamma\": [0.0001, 0.001, 0.01, 0.1]}\n",
    "               }\n",
    "\n",
    "# performance metrics\n",
    "perf_metrics = {\"Accuracy\": metrics.accuracy_score, \n",
    "                \"Precision\": metrics.precision_score, \n",
    "                \"Recall\": metrics.recall_score,\n",
    "               # \"AUC\": metrics.roc_auc_score, \n",
    "                \"F1-Score\": metrics.f1_score, \n",
    "               # \"Brier\": metrics.brier_score_loss\n",
    "               }\n",
    "scorer_metrics = {}\n",
    "for pf in perf_metrics:\n",
    "    scorer_metrics[pf] = metrics.make_scorer(perf_metrics[pf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-allocation\n",
    "X, y = df_model_medium.drop(labels=output_variable, axis=1).values, df_model_medium[output_variable].values\n",
    "k, z, innercv_results, inner_best_model = 0, 0, {}, {}\n",
    "df_outer_results = pd.DataFrame(index=[0], columns=[\"Model\", \"Time\"] + list(perf_metrics.keys()))\n",
    "\n",
    "# outer loop\n",
    "for (out_train, out_test) in outer_folds.split(X, y):\n",
    "    # separation: train, test\n",
    "    Xtrain, Xtest = X[out_train], X[out_test]\n",
    "    ytrain, ytest = y[out_train], y[out_test]\n",
    "    \n",
    "    # inner loop -- all models\n",
    "    innercv_results[\"fold_\" + str(k)] = {}\n",
    "    inner_best_model[\"fold_\" + str(k)] = {}\n",
    "    start, end = [], []\n",
    "    for class_model in model_dict.keys():\n",
    "        start.append(time())\n",
    "        print((k, class_model))\n",
    "        innercv_results[\"fold_\" + str(k)][class_model] = GridSearchCV(estimator=model_dict[class_model], \n",
    "                                                                       param_grid=hyper_params[class_model], \n",
    "                                                                       scoring=scorer_metrics, \n",
    "                                                                       cv=inner_folds, \n",
    "                                                                       refit=\"F1-Score\")\n",
    "        innercv_results[\"fold_\" + str(k)][class_model].fit(Xtrain, ytrain.ravel())\n",
    "        inner_best_model[\"fold_\" + str(k)][class_model] = innercv_results[\"fold_\" + str(k)][class_model].best_estimator_\n",
    "        end.append(time())\n",
    "    \n",
    "    # outer loop prediction\n",
    "    for (v, class_model) in enumerate(model_dict.keys()):\n",
    "        # prediction\n",
    "        ypred_class = inner_best_model[\"fold_\" + str(k)][class_model].predict(Xtest)\n",
    "        df_outer_results.loc[z, \"Model\"] = class_model\n",
    "        df_outer_results.loc[z, \"Time\"] = end[v] - start[v]\n",
    "    \n",
    "        # compute performance metrics\n",
    "        for pf in perf_metrics.keys():\n",
    "            df_outer_results.loc[z, pf] = perf_metrics[pf](ytest, ypred_class)\n",
    "        z += 1\n",
    "    \n",
    "    # iteration\n",
    "    k += 1\n",
    "\n",
    "# final organisation\n",
    "df_outer_results[list(perf_metrics.keys()) + [\"Time\"]] = df_outer_results[list(perf_metrics.keys()) + [\"Time\"]].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer_results.pivot_table(index=[\"Model\"], aggfunc=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Gaussian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://gpytorch.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Hyperparameter optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://scikit-optimize.github.io/#skopt.gp_minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree of Parzen Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://github.com/hyperopt/hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolutionary Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://deap.readthedocs.io/en/master/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainable Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainable Boosting Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://github.com/microsoft/interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://github.com/slundberg/shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://github.com/marcotcr/lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://github.com/pytorch/captum?fbclid=IwAR0P_CvwX-dkUztoUBrcfFDygGGIHRt775pwik86npEUiKuUKudtx55kRDw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation schemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://github.com/askoshiyama/tsdata-mvapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn for time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://github.com/alan-turing-institute/sktime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon GluonTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://github.com/awslabs/gluon-ts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
