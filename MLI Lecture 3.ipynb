{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirements !pip freeze > requirements.txt.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Organise data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/askoshiyama/mli-cohort/master/german_credit.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variables\n",
    "cat_variables = ['account_check_status', 'credit_history', 'purpose', 'savings', 'present_emp_since', 'personal_status_sex',\n",
    "                'property', 'other_installment_plans', 'housing', 'job', 'telephone', \"other_debtors\", 'foreign_worker']\n",
    "\n",
    "# target variable\n",
    "output_variable = [\"default\"]\n",
    "\n",
    "# other integer variables\n",
    "int_variables = ['credits_this_bank', 'present_res_since', 'duration_in_month', 'people_under_maintenance', \n",
    "                 'installment_as_income_perc', 'age', 'credit_amount']\n",
    "# list(set(df.columns) - set(output_variable) - set(cat_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping categorical variables to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = [\"cat\", \"dog\", \"cat\", \"dog\"]\n",
    "# one-hot encoding\n",
    "animals_cat = [1, 0, 1, 0]\n",
    "animals_dog = [0, 1, 0, 1]\n",
    "animals_not_cat = [0, 1, 0, 1] # 1 - animals_cat\n",
    "\n",
    "# integer encoding\n",
    "animals_int = [1, 2, 1, 2]\n",
    "\n",
    "# binary encoding\n",
    "animals = [\"cat\", \"dog\", \"cat\", \"dog\", \"rat\", \"bat\"] # 4 categories, log_2 (4) = 2\n",
    "animals_0 = [0,     0,    0,      0,     1,     1]\n",
    "animals_1 = [0,     1,    0,      1,     0,     1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-allocation\n",
    "df_cat = pd.DataFrame(index=df.index)\n",
    "\n",
    "# one-hot encoding of categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# I will do a loop for pedagogical reasons, but it is not entirely necessary\n",
    "for cat in cat_variables:\n",
    "    # one-hot encoding fitting\n",
    "    one_hot_func = OneHotEncoder().fit(df[[cat]])\n",
    "    \n",
    "    # mapping\n",
    "    cat_mapped = one_hot_func.transform(df[[cat]]).toarray()\n",
    "    \n",
    "    # storing\n",
    "    for (k, cat_label) in enumerate(one_hot_func.categories_[0]):\n",
    "        df_cat[cat + \"_\" + cat_label] = cat_mapped[:, k]\n",
    "\n",
    "# quick check\n",
    "df_cat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bracketing integer variable - age\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbin_func = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='quantile').fit(df[[\"age\"]])\n",
    "df_age = pd.DataFrame(kbin_func.transform(df[[\"age\"]]).toarray(), columns=[\"young\", \"adult\", \"senior\"])\n",
    "\n",
    "# checking\n",
    "pd.concat([df_age, df[[\"age\"]]], axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other types of transformations possible - log transformation \n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "log_mapping = FunctionTransformer(func=np.log, inverse_func=np.exp)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.hist(df[\"credit_amount\"])\n",
    "ax1.set_title(\"Pre-transformation\")\n",
    "\n",
    "ax2.hist(log_mapping.transform(df[\"credit_amount\"]))\n",
    "ax2.set_title(\"After log-transformation\")\n",
    "df_log = pd.DataFrame(log_mapping.transform(df[[\"credit_amount\"]]).values, columns=[\"log(credit)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidating a final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.concat([df[int_variables], df_cat, df_age, df_log, df[output_variable]], axis=1)\n",
    "df.shape, df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick modelling with Tree-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model[output_variable].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data\n",
    "X, y = df_model.drop(labels=output_variable, axis=1), df_model[output_variable]\n",
    "\n",
    "# fit model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#class_tree = DecisionTreeClassifier(max_depth=2, criterion=\"gini\")\n",
    "class_tree = DecisionTreeClassifier(max_depth=5, criterion=\"gini\", class_weight=\"balanced\")\n",
    "class_tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting node variables + Plotting Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(class_tree, out_file=\"class_tree.dot\", feature_names=X.columns, \n",
    "                class_names = [\"No Default\", \"Default\"], rounded = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### go to http://webgraphviz.com/ and paste class_tree.dot text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(X[\"account_check_status_no checking account\"] <=0.5, y[output_variable[0]]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodefault_duration = X.loc[((y.values == 0) & \n",
    "                            (X[\"account_check_status_no checking account\"].values.reshape(-1, 1) <= 0.5)).reshape(1, -1)[0], \n",
    "                           \"duration_in_month\"]\n",
    "default_duration = X.loc[((y.values == 1) & \n",
    "                          (X[\"account_check_status_no checking account\"].values.reshape(-1, 1) <= 0.5)).reshape(1, -1)[0], \n",
    "                         \"duration_in_month\"]\n",
    "ax = sns.kdeplot(nodefault_duration, shade=True, shade_lowest=False, label=\"No Default\")\n",
    "ax = sns.kdeplot(default_duration, shade=True, shade_lowest=False, label=\"Default\")\n",
    "ax.set_xlabel(\"duration_in_month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validating Tree-Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "#from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 10-fold cv\n",
    "k_folds = StratifiedKFold(n_splits=10, random_state=10)\n",
    "\n",
    "# performance metrics\n",
    "perf_metrics = {\"Accuracy\": metrics.accuracy_score, \n",
    "                \"Precision\": metrics.precision_score, \n",
    "                \"Recall\": metrics.recall_score,\n",
    "                \"AUC\": metrics.roc_auc_score, \n",
    "                \"F1-Score\": metrics.f1_score, \n",
    "                \"Brier\": metrics.brier_score_loss\n",
    "               }\n",
    "\n",
    "# model\n",
    "#model = DecisionTreeClassifier(max_depth=3, criterion=\"gini\", random_state=10)\n",
    "model = DecisionTreeClassifier(max_depth=2, criterion=\"gini\", class_weight=\"balanced\", random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-allocation\n",
    "X, y = df_model.drop(labels=output_variable, axis=1).values, df_model[output_variable].values\n",
    "df_metrics = pd.DataFrame(index=range(10), columns=perf_metrics.keys())\n",
    "\n",
    "# main loop\n",
    "k = 0\n",
    "for (train, test) in k_folds.split(X, y):\n",
    "    # fit model\n",
    "    model.fit(X[train], y[train])\n",
    "       \n",
    "    # test model\n",
    "    ypred_class = model.predict(X[test])\n",
    "    ypred_prob = model.predict_proba(X[test])[:, 1]\n",
    "\n",
    "    # compute performance metrics\n",
    "    for pf in perf_metrics.keys():\n",
    "        if pf in [\"AUC\", \"Brier\"]:\n",
    "            df_metrics.loc[k, pf] = perf_metrics[pf](y[test], ypred_prob)\n",
    "        else:\n",
    "            df_metrics.loc[k, pf] = perf_metrics[pf](y[test], ypred_class)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning + Cross-validation: GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# params\n",
    "k_folds = StratifiedKFold(n_splits=10, random_state=10) # k-fold\n",
    "hyper_params = {\"learning_rate\": [10.0 ** -2, 0.5, 10.0 ** -1, 1.5, 10.0 ** 0],\n",
    "                \"max_depth\": [1, 2, 3],\n",
    "                \"max_features\": [0.1, 0.25, 0.5],\n",
    "                \"n_estimators\": [50, 100]\n",
    "                }\n",
    "\n",
    "# performance metrics\n",
    "perf_metrics = {\"Accuracy\": metrics.accuracy_score, \n",
    "                \"Precision\": metrics.precision_score, \n",
    "                \"Recall\": metrics.recall_score,\n",
    "                \"AUC\": metrics.roc_auc_score, \n",
    "                \"F1-Score\": metrics.f1_score, \n",
    "                \"Brier\": metrics.brier_score_loss}\n",
    "\n",
    "for pf in perf_metrics:\n",
    "    perf_metrics[pf] = metrics.make_scorer(perf_metrics[pf])\n",
    "\n",
    "# main method\n",
    "X, y = df_model.drop(labels=output_variable, axis=1).values, df_model[output_variable].values\n",
    "\n",
    "model = GridSearchCV(estimator=GradientBoostingClassifier(random_state=10), \n",
    "                     param_grid=hyper_params, \n",
    "                     scoring=perf_metrics, \n",
    "                     cv=k_folds, \n",
    "                     refit=\"F1-Score\")\n",
    "\n",
    "model.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best model\n",
    "best_model = model.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all results and avg results in a df\n",
    "df_cv = pd.DataFrame(model.cv_results_)\n",
    "\n",
    "# add a hyperparameter column in avg df\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "df_hyperparams = pd.DataFrame(list(ParameterGrid(model.param_grid)))\n",
    "df_avgcv = pd.DataFrame(columns=perf_metrics.keys())\n",
    "for pf in perf_metrics.keys():\n",
    "    df_avgcv[pf] = df_cv[\"mean_test_\" + pf]\n",
    "df_avgcv = pd.concat([df_hyperparams, df_avgcv], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=\"max_depth\", y=\"F1-Score\", data=df_avgcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avgcv.loc[df_avgcv[\"F1-Score\"].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featimp = pd.DataFrame({\"Variable\": df_model.drop(output_variable, axis=1).columns,\n",
    "                           \"Importance\": best_model.feature_importances_})\n",
    "df_featimp = df_featimp.sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "# chart\n",
    "df_featimp.iloc[:5].plot(x=\"Variable\", y=\"Importance\", kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial dependency plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_partial_dependence(best_model, X, df_featimp.iloc[:5].index, response_method=\"predict_proba\", \n",
    "                        method=\"brute\", grid_resolution=200, ax=ax, \n",
    "                        feature_names=df_featimp[\"Variable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "plot_partial_dependence(best_model, X, [(df_featimp.index[0], df_featimp.index[1])], \n",
    "                        feature_names=df_featimp[\"Variable\"], ax=ax, \n",
    "                        response_method=\"predict_proba\", method=\"brute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning + Cross-validation: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# params\n",
    "k_folds = StratifiedKFold(n_splits=10, random_state=10) # k-fold\n",
    "hyper_params = {\"max_depth\": [1, 3, 7, None],\n",
    "                \"max_features\": [0.1, 0.25, 0.5],\n",
    "                \"n_estimators\": [200]\n",
    "                }\n",
    "\n",
    "# performance metrics\n",
    "perf_metrics = {\"Accuracy\": metrics.accuracy_score, \n",
    "                \"Precision\": metrics.precision_score, \n",
    "                \"Recall\": metrics.recall_score,\n",
    "                \"AUC\": metrics.roc_auc_score, \n",
    "                \"F1-Score\": metrics.f1_score, \n",
    "                \"Brier\": metrics.brier_score_loss}\n",
    "\n",
    "for pf in perf_metrics:\n",
    "    perf_metrics[pf] = metrics.make_scorer(perf_metrics[pf])\n",
    "\n",
    "# main method\n",
    "X, y = df_model.drop(labels=output_variable, axis=1).values, df_model[output_variable].values\n",
    "\n",
    "model = GridSearchCV(estimator=RandomForestClassifier(random_state=10), \n",
    "                     param_grid=hyper_params, \n",
    "                     scoring=perf_metrics, \n",
    "                     cv=k_folds, \n",
    "                     refit=\"F1-Score\")\n",
    "\n",
    "model.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best model\n",
    "best_model = model.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all results and avg results in a df\n",
    "df_cv = pd.DataFrame(model.cv_results_)\n",
    "\n",
    "# add a hyperparameter column in avg df\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "df_hyperparams = pd.DataFrame(list(ParameterGrid(model.param_grid)))\n",
    "df_avgcv = pd.DataFrame(columns=perf_metrics.keys())\n",
    "for pf in perf_metrics.keys():\n",
    "    df_avgcv[pf] = df_cv[\"mean_test_\" + pf]\n",
    "df_avgcv = pd.concat([df_hyperparams, df_avgcv], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=\"max_depth\", y=\"F1-Score\", data=df_avgcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avgcv.loc[df_avgcv[\"F1-Score\"].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featimp = pd.DataFrame({\"Variable\": df_model.drop(output_variable, axis=1).columns,\n",
    "                           \"Importance\": best_model.feature_importances_})\n",
    "df_featimp = df_featimp.sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "# chart\n",
    "df_featimp.iloc[:5].plot(x=\"Variable\", y=\"Importance\", kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial dependency plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_partial_dependence(best_model, X, df_featimp.iloc[:5].index, response_method=\"predict_proba\", \n",
    "                        method=\"brute\", grid_resolution=200, ax=ax, \n",
    "                        feature_names=df_featimp[\"Variable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "plot_partial_dependence(best_model, X, [(df_featimp.index[0], df_featimp.index[1])], \n",
    "                        feature_names=df_featimp[\"Variable\"], ax=ax, \n",
    "                        response_method=\"predict_proba\", method=\"brute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalable models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset with different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small\n",
    "df_model_small = df_model.copy()\n",
    "\n",
    "# medium\n",
    "for k in range(10):\n",
    "    if k==0:\n",
    "        df_model_medium = df_model.copy()\n",
    "    else:\n",
    "        df_model_medium = pd.concat([df_model_medium, df_model.copy()], axis=0, ignore_index=True)\n",
    "        \n",
    "# large\n",
    "for k in range(100):\n",
    "    if k==0:\n",
    "        df_model_large = df_model.copy()\n",
    "    else:\n",
    "        df_model_large = pd.concat([df_model_large, df_model.copy()], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# small\n",
    "start = time()\n",
    "GradientBoostingClassifier(n_estimators=100).fit(df_model_small.drop(output_variable, axis=1), \n",
    "                                                 df_model_small[output_variable])\n",
    "print(time() - start)\n",
    "\n",
    "# medium\n",
    "start = time()\n",
    "GradientBoostingClassifier(n_estimators=100).fit(df_model_medium.drop(output_variable, axis=1), \n",
    "                                                 df_model_medium[output_variable])\n",
    "print(time() - start)\n",
    "\n",
    "# large\n",
    "start = time()\n",
    "GradientBoostingClassifier(n_estimators=100).fit(df_model_large.drop(output_variable, axis=1), \n",
    "                                                 df_model_large[output_variable])\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM - https://lightgbm.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm - install it first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from time import time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# small\n",
    "start = time()\n",
    "LGBMClassifier(n_estimators=100).fit(df_model_small.drop(output_variable, axis=1).values, \n",
    "                                                 df_model_small[output_variable].values)\n",
    "print(time() - start)\n",
    "\n",
    "# medium\n",
    "start = time()\n",
    "LGBMClassifier(n_estimators=100).fit(df_model_medium.drop(output_variable, axis=1).values, \n",
    "                                                 df_model_medium[output_variable].values)\n",
    "print(time() - start)\n",
    "\n",
    "# large\n",
    "start = time()\n",
    "LGBMClassifier(n_estimators=100).fit(df_model_large.drop(output_variable, axis=1).values, \n",
    "                                                 df_model_large[output_variable].values)\n",
    "print(time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
